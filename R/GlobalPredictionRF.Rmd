---
title: "Predicting Global Rs Partitioning Using Random Forest Modeling"
author: "Max Frissell"
date: "8/13/20"
output: html_document
---

```{r Packages, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

library(dplyr)
library(tidyr)
library(ggplot2)
theme_set(theme_minimal())
library(here)
library(raster)
library(randomForest)
library(caret)
```

```{r SRDBSetup, include = FALSE}
## Selects the lines I want to use from the SRDB

# Read in entire SRDB and pull only desired columns, removing rows with missing values
read.csv(here::here("Data", "srdb-data.csv")) %>%
  dplyr::select(Site_ID, Latitude, Longitude, Rs_annual, RC_annual, Manipulation, warner_rs) %>%
  filter(!is.na(Site_ID), !is.na(Latitude), !is.na(Longitude),
         !is.na(Rs_annual), RC_annual > 0, RC_annual < 1, 
         !is.na(RC_annual), Manipulation == "None", !is.na(warner_rs)) -> srdb

# Rename warner_rs variable to Rs_warner to fit with the other variables' names
srdb <- dplyr::rename(srdb, Rs_warner = warner_rs)
```

```{r PullingFromWC2, cashe = TRUE}
## This chunk pulls climate data from WorldClim2 and makes some graphs from the mean annual temperature and precipitation data

# Download worldclim data for precip and tmean if necessary, into w10/ folder
precip <- getData("worldclim", path = here::here(), var = "prec", res = 10, download = !file.exists("wc10/prec1.hdr"))
tmean <- getData("worldclim", path = here::here(), var = "tmean", res = 10, download = !file.exists("wc10/wc10/tmean1.hdr"))

# Pull out cosore dataset latitudes and longitudes
srdb %>%
  dplyr::select(Site_ID, Longitude, Latitude) -> srdb_coords

# MAP data that matches the srdb coordinates
raster::extract(precip, srdb_coords[2:3]) -> precip_coords
apply(precip_coords, 1, sum) -> MAP

# The same for MAT
raster::extract(tmean, srdb_coords[2:3]) -> tmean_vals
apply(tmean_vals, 1, mean) -> MAT

# Temp data is stored in degC * 10, so we need to divide to get back to degC
MAT <- MAT / 10

# Add the worldclim MAT and MAP values to the srdb data and remove missing values
allData <- cbind(srdb, MAT, MAP)
allData <- allData[!is.na(MAT),]
```

``` {r ExtractingMyco}
## Extracts data on mycorrhizae for each SRDB point from global dataset from Soudzilovskaia et al. 2019
## Note: the .TIF files used here::here are not included in the repo and were downloaded from https://github.com/nasoudzilovskaia/Soudzilovskaia_NatureComm_MycoMaps/tree/master/Maps_Myco_veg_current on 7/14/20

# Get all of the global data for each type of myco (again, files are pre-downloaded and not in the GitHub repo)
am = raster(here::here("Data", "MycDistrAM_current.TIF"))
em = raster(here::here("Data", "MycDistrEM_current.TIF"))
er = raster(here::here("Data", "MycDistrER_current.TIF"))
nm = raster(here::here("Data", "MycDistrNM_current.TIF"))

# Extract the myco data for each coordinate pair in the SRDB database and add it to the rest of the data
AM_percent = raster::extract(am, allData[, c(3, 2)])
EM_percent = raster::extract(em, allData[, c(3, 2)])
ER_percent = raster::extract(er, allData[, c(3, 2)])
NM_percent = raster::extract(nm, allData[, c(3, 2)])
allData = cbind(allData, AM_percent, EM_percent, ER_percent, NM_percent)

# Throw out the entries where::here there::here isn't myco data
allData = allData[!is.na(allData$AM_percent),]
```

``` {r ExtractingBiomass}
## Extracts data on above and below ground biomass for each SRDB point from global dataset from Spawn et al. 2020
## Note: the .TIF files used are not included in the repo and were downloaded from https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1763 on 7/15/20

# Extract above and belowground data for each location
raster(here::here("Data", "aboveground_biomass_carbon_2010.tif")) %>%
  raster::extract(allData[, c(3, 2)]) -> BM_aboveground
raster(here::here("Data", "belowground_biomass_carbon_2010.tif")) %>%
  raster::extract(allData[, c(3, 2)]) -> BM_belowground

# Add these biomass values to the larger dataset
allData <- cbind(allData, BM_aboveground, BM_belowground)

# Remove values where::here there::here are no biomass data
allData <- allData[!is.na(allData$BM_aboveground) & !is.na(allData$BM_belowground),]
```

``` {r ExtractingNDep}
## Extracts N deposition data for each srdb point

# Pull N-dep values for every coordinate pair in the SRDB
raster(here::here("Data", "sdat_830_2_20200721_153826639.asc")) %>%
  raster::extract(allData[, c(3, 2)]) -> N_dep_1993

# Add this to the data pool and remove entries without N-dep data
allData <- cbind(allData, N_dep_1993)[!is.na(N_dep_1993),]
```

``` {r ExtractingIGBP}
## Extracts climate and vegetation data from IGBP Koppen MODIS

IGBP_Koppen_MODIS <- read.csv(here::here("Data", "IGBP_Koppen_MODIS.csv"))

# Regroup climate data into fewer categories for easier analysis
IGBP_Koppen_MODIS %>% 
  mutate(MiddleClimate = case_when(
    ClimateTypes %in% c("Af", "Am", "As", "Aw") ~ "A",
    ClimateTypes %in% c("BSh", "BSk", "BWh", "BWk") ~ "B",
    ClimateTypes %in% c("Cfa", "Cfb", "Cfc") ~ "Cf",
    ClimateTypes %in% c("Csa", "Csb", "Csc") ~ "Cs",
    ClimateTypes %in% c("Cwa", "Cwb", "Cwc") ~ "Cw",
    ClimateTypes %in% c("Dfa", "Dfb", "Dfc", "Dfd") ~ "Df",
    ClimateTypes %in% c("Dsa", "Dsb", "Dsc", "Dwa", "Dwb", "Dwc", "Dwd") ~ "Dsw",
    ClimateTypes %in% c("EF", "ET") ~ "E",
    TRUE ~ "Other")) -> IGBP_Koppen_MODIS

# Change Latitude and Longitude to the same 0.5*0.5 resolution as in the dataset
allData %>% 
  mutate(Latitude2 = round(Latitude * 2) / 2 + 0.25, 
         Longitude2 = round(Longitude * 2) / 2 + 0.25) %>% 
  # Add data to the large dataset
  left_join(IGBP_Koppen_MODIS, by = c("Latitude2" = "Latitude",
                                      "Longitude2" = "Longitude")) %>% 
  # Remove data I don't want anymore and NAs
  dplyr::select(-Latitude2, -Longitude2, -IGBP, -Ecosystem, -ClimateTypes, -barren_yn, -warner_rs) ->
  allData
```

``` {r RandomForest}
## Make a random forest model to predict RC_annual from all of the data

# set seed for reproducibility
set.seed(698541985)

# Add the absolute value of latitude to the dataset
allData$absLat <- abs(allData$Latitude)

# Make sure there is no missing data
allData <- allData[complete.cases(allData),]

# randomForest requires factor predictors, not characters
allData$MiddleClimate <- as.factor(allData$MiddleClimate)

# Make a random forest model
model <- randomForest(RC_annual ~
                       absLat +
                       Rs_warner +
                       MAT + MAP +
                       AM_percent + EM_percent + ER_percent + NM_percent +
                       BM_aboveground + BM_belowground +
                       N_dep_1993 +
                       IGBP_group + Ecosystem2 + MiddleClimate,
                     data = allData,
                     importance = TRUE, 
                     proximity = TRUE,
                     na.action = na.exclude)
```

```{r InvestigateModel}
## Investigate how well the first model works

# Predict allData RC's using the model
prediction <- predict(model, allData)
withP <- cbind(allData, prediction)

# Plot these predictions vs the true values
ggplot(withP, aes(x = prediction, y = RC_annual)) +
  lims(x = c(0, 1)) +
  geom_point() +
  geom_smooth(method = lm) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", size = 1, color = "red")

# Calculate the residuals and make a residuals plot
residuals <- withP$RC_annual - withP$prediction
withP <- cbind(withP, residuals)
ggplot(withP, aes(x = prediction, y = residuals)) +
  lims(x = c(0, 1)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 1, color = "red")
```

``` {r ModelTuning}
## This Will investigate certain facets of the model and tweak how it was made to hopefully make more accurate predictions

# Plot how much adding more trees affected the accuracy
plot(model)

# Tune with different mtry values
tuneRF(subset(allData, select = -c(RC_annual, Site_ID, Longitude, Latitude, Manipulation)), 
       allData[, 5],
       stepFactor = 2,
       plot = TRUE,
       ntreetry = 200, # Based on the plot above, 200 trees seems reasonable
       trace = TRUE,
       improve = 0.01)
```

``` {r ImproveModel}
## replace the old model with a new one, created using the settings that the tuning graphs show are the best

model <- randomForest(RC_annual ~
                       absLat +
                       Rs_warner +
                       MAT + MAP +
                       AM_percent + EM_percent + ER_percent + NM_percent +
                       BM_aboveground + BM_belowground +
                       N_dep_1993 +
                       IGBP_group + Ecosystem2 + MiddleClimate,
                     data = allData,
                     mtry = 2, # 2 has the least error in the tuning graph
                     ntree = 200, # After ~200 trees, adding more trees doesn't seem to make a difference
                     importance = TRUE, 
                     proximity = TRUE,
                     na.action = na.exclude)
```

``` {r InvestigateImproved}
## Investigate how well the improved model works

# Predict allData RC's using the model
prediction <- predict(model, allData)
withP <- cbind(allData, prediction)

# Plot these predictions vs the true values
ggplot(withP, aes(x = prediction, y = RC_annual)) +
  lims(x = c(0, 1)) +
  geom_point() +
  geom_smooth(method = lm) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", size = 1, color = "red")

# Calculate the residuals and make a residuals plot
residuals <- withP$RC_annual - withP$prediction
withP <- cbind(withP, residuals)
ggplot(withP, aes(x = prediction, y = residuals)) +
  lims(x = c(0, 1)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 0, linetype = "dashed", size = 1, color = "red")

# Look at how well the model predicts RC using a linear regression model on the RF model output
lm <- lm(RC_annual ~ prediction, data = withP)
summary(lm)
```

``` {r Importance}
## Look at which predictors are the most important

varImpPlot(model)
"absLat, Rs_warner, MAT, MAP, AM_percent, EM_percent, ER_percent, NM_percent, BM_aboveground, BM_belowground, N_dep_1993, IGBP_group, Ecosystem2, MiddleClimate"
varUsed(model)
```

Note: this is not representative of how good this model is a predicting RC values that it has never seen before; 
this only speaks to its ability to predict RC values that it was trained with and trained to be able to predict to the best of its ability.
As seen with other models produced using only some of this data, this model would perform significantly worse when given data it wasn't trained with.

``` {r PullingGlobalLatLong}
## Pull a global set of coordinates for all land and ecosystem data for those coords

# Read it all in from csv
globalData <- read.csv(here::here("Data", "IGBP_Koppen_MODIS.csv"))

# Regroup climate data into fewer categories for easier analysis
globalData %>% 
  mutate(MiddleClimate = case_when(
    ClimateTypes %in% c("Af", "Am", "As", "Aw") ~ "A",
    ClimateTypes %in% c("BSh", "BSk", "BWh", "BWk") ~ "B",
    ClimateTypes %in% c("Cfa", "Cfb", "Cfc") ~ "Cf",
    ClimateTypes %in% c("Csa", "Csb", "Csc") ~ "Cs",
    ClimateTypes %in% c("Cwa", "Cwb", "Cwc") ~ "Cw",
    ClimateTypes %in% c("Dfa", "Dfb", "Dfc", "Dfd") ~ "Df",
    ClimateTypes %in% c("Dsa", "Dsb", "Dsc", "Dwa", "Dwb", "Dwc", "Dwd") ~ "Dsw",
    ClimateTypes %in% c("EF", "ET") ~ "E",
    TRUE ~ "Other")) %>% 
# Get rid of redundant/unhelpful data
  dplyr::select(-IGBP, -Ecosystem, -ClimateTypes, -barren_yn) %>% 
# Rename warner_rs variable to Rs_warner to fit with the other variables
  rename(Rs_warner = warner_rs) -> 
  globalData
```

``` {r GlobalPullFromWC2}
## Pull climate data from WorldClim2 for global coords

# Extract precip values
raster::extract(precip, globalData[c(2, 1)]) %>%
  apply(1, sum) -> MAP

# Extract temp values
raster::extract(tmean, globalData[c(2, 1)]) %>%
  apply(1, mean) -> MAT

# Temp data is stored in degC * 10, so we need to divide to get back to degC
MAT <- MAT / 10

# Add it to the dataframe
globalData <- cbind(globalData, MAP, MAT)
```

``` {r GlobalPullFromMyco}
## Pull mycorrhizae data for global coords

# Extract the myco data for each coordinate pair add it to the rest of the data
AM_percent <- raster::extract(am, globalData[, c(2, 1)])
EM_percent <- raster::extract(em, globalData[, c(2, 1)])
ER_percent <- raster::extract(er, globalData[, c(2, 1)])
NM_percent <- raster::extract(nm, globalData[, c(2, 1)])
globalData <- cbind(globalData, AM_percent, EM_percent, ER_percent, NM_percent)
```

``` {r GlobalPullFromBiomass}
## Pull biomass data for global coords

# Extract above and belowground data for each location
raster(here::here("Data", "aboveground_biomass_carbon_2010.tif")) %>%
  raster::extract(globalData[, c(2, 1)]) -> BM_aboveground
raster(here::here("Data", "belowground_biomass_carbon_2010.tif")) %>%
  raster::extract(globalData[, c(2, 1)]) -> BM_belowground

# Add biomass to the dataframe
globalData <- cbind(globalData, BM_aboveground, BM_belowground)
```

``` {r GlobalPullFromNDep}
## Pull N deposition data for global coords

# Pull N-dep values for every coordinate pair
raster(here::here("Data", "sdat_830_2_20200721_153826639.asc")) %>%
  raster::extract(globalData[, c(2, 1)]) -> N_dep_1993

# Add it to the dataframe
globalData <- cbind(globalData, N_dep_1993)
```

``` {r MappingAndRemoving}
## Map all coordinate points and see how they change as NA data is removed, also remove data the model doesn't understand

# Plot starting global grid of coords
ggplot(globalData, aes(x = Longitude, y = Latitude)) +
  geom_point(size = 0.3) +
  lims(x = c(-180, 180), y = c(-90, 90))

# Get rid of points with missing warner Rs, myco, and climate data
globalData <- globalData[complete.cases(globalData),]

# Plot again
ggplot(globalData, aes(x = Longitude, y = Latitude)) +
  geom_point(size = 0.3) +
  lims(x = c(-180, 180), y = c(-90, 90))

# Plot Global Warner
ggplot(globalData, aes(x = Longitude, y = Latitude, color = Rs_warner)) +
  geom_point(size = 0.3) +
  lims(x = c(-180, 180), y = c(-90, 90))
```

``` {r GlobalPrediction}
## Predict global RC

# As before, need to change a few things in data frame
globalData$absLat <- abs(globalData$Latitude)
globalData$MiddleClimate <- as.factor(globalData$MiddleClimate)

# Predict it
globalData$prediction <- predict(model, globalData)

# Make the default theme have a centered title
theme_update(plot.title = element_text(hjust = 0.5))

# Plot predictions globally
ggplot(globalData, aes(Longitude, Latitude, color = prediction)) + 
  geom_point(size = 0.3) +
  lims(x = c(-180, 180), y = c(-90, 90)) +
  labs(color = "RC prediction") +
  ggtitle("Global RC Predictions") +
  scale_color_viridis_c()

# Look at the distribution of predictions
ggplot(globalData, aes(x = prediction)) +
  geom_histogram(color = "black", fill = "lightgrey") +
  labs(x = "RC Prediction")
```